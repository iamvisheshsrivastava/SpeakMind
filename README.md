[![Progress: In Progress](https://img.shields.io/badge/Progress-%F0%9F%9A%A7%20In%20Progress-orange?style=flat-square)]()

# SpeakMind

An advanced conversational AI assistant inspired by ChatGPT â€” built for **contextâ€‘aware, multiâ€‘turn interactions** with a clean Streamlit UI and a FastAPI backend.

<p align="center">
  <img src="assets/ui_screenshot.png" alt="SpeakMind UI" width="900" />
</p>

> **Status:** ğŸ”„ In Development
>
> ```text
> [â–ˆâ–ˆ------------------] 10% Complete
> ```

---

## ğŸš€ Features

* **Multiâ€‘turn Conversations** with session memory (mock + real LLM modes)
* **Configurable System Prompt** from the UI
* **FastAPI Backend** exposing `/` (health) and `/query` endpoints
* **Streamlit Frontend** with retry-on-failure and connection status
* **Modular Agents** (LangChain powered; extendable tools)
* **Containerâ€‘ready** (easy path to Docker + cloud)

---

## ğŸ§° Tech Stack

**Python 3.9+**

**Frameworks & Libraries**

* FastAPI, Uvicorn
* Streamlit, Requests
* LangChain (+ tools)
* (Optional) OpenAI / Together.ai SDKs

**Infra & Tooling**

* Docker (optional)
* Render / Railway / Fly.io (FastAPI)
* Streamlit Cloud (Streamlit)

---

## ğŸ—‚ï¸ Repository Structure

```
SpeakMind/
â”œâ”€ ai_agent.py          # Simple Together/OpenAI agent (CLI helper)
â”œâ”€ app_ui.py            # Streamlit UI (frontend)
â”œâ”€ app.py               # FastAPI backend (real API)
â”œâ”€ config.py            # Config + env variables
â”œâ”€ mock_backend.py      # Mock FastAPI server (no API keys required)
â”œâ”€ multi_agent.py       # LangChain multiâ€‘agent CLI demo
â”œâ”€ requirements.txt     # Python dependencies
â”œâ”€ assets/              # ğŸ“¸ Screenshots & images for README
â”‚  â””â”€ ui_screenshot.png
â””â”€ README.md
```

---

## ğŸ“ˆ Architecture

```mermaid
flowchart TD
  UI[Streamlit UI] -->|HTTP /query| API[FastAPI Backend]
  API -->|Invoke| AGT[Agents / LangChain]
  AGT -->|Calls| LLM[LLM Providers]
  AGT -->|Response| API
  API -->|JSON| UI
```

---

## ğŸ”§ Setup & Run (Local)

### 1) Create & activate venv

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
# source venv/bin/activate
```

### 2) Install dependencies

```bash
python -m pip install --upgrade pip
python -m pip install -r requirements.txt
```

### 3) (Optional) Configure API keys

Create a `.env` file in the repo root if youâ€™ll use real LLMs:

```
OPENAI_API_KEY=sk-...
TOGETHER_API_KEY=...
```

### 4a) **Mock mode** (no keys needed)

Run the mock backend:

```bash
python mock_backend.py
# â†’ serves at http://127.0.0.1:9000
```

Then start the UI in a new terminal:

```bash
streamlit run app_ui.py
# â†’ http://localhost:8501
```

### 4b) **Real backend** (FastAPI)

Run FastAPI instead of the mock:

```bash
uvicorn app:app --host 127.0.0.1 --port 9000 --reload
```

Then start the UI:

```bash
streamlit run app_ui.py
```

> The UI calls the backend at `http://127.0.0.1:9000`. To target a deployed API, update the base URL inside `app_ui.py`.

---

## ğŸ”Œ API Endpoints (FastAPI)

* `GET /` â†’ health: `{ "message": "..." }`
* `GET /query?query=...&prompt=...` â†’ returns `{ "response": "..." }`

**cURL:**

```bash
curl "http://127.0.0.1:9000/query?query=Hello&prompt=You%20are%20helpful"
```

---

## â˜ï¸ Deployment (Freeâ€‘friendly)

You can deploy **frontend and backend separately**:

### Streamlit (frontend)

* **Streamlit Cloud** â†’ connect GitHub â†’ main file: `app_ui.py`

### FastAPI (backend)

* **Render** (free web service) / **Railway** / **Deta Space** / **Fly.io**
* Start command: `uvicorn app:app --host 0.0.0.0 --port 10000` (or platformâ€™s port)

### Point the UI to your backend

In `app_ui.py`, replace the base URL:

```python
# Example
BASE_URL = "https://speakmind-backend.onrender.com"
```

### CORS for crossâ€‘origin calls

Add this to `app.py`:

```python
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # tighten to your Streamlit domain in prod
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

---

## ğŸ¤ Contributing

1. Fork the repo
2. Create a feature branch: `git checkout -b feature-name`
3. Commit: `git commit -m "feat: add <feature>"`
4. Push: `git push origin feature-name`
5. Open a Pull Request

---

## ğŸ§­ Roadmap

* [ ] Vector memory (FAISS) for longâ€‘term conversation
* [ ] Tooling: web search, docs RAG, calculators
* [ ] Docker + dockerâ€‘compose for oneâ€‘command local stack
* [ ] CI (lint/test) & preâ€‘commit hooks
* [ ] Auth + rate limiting

---

## ğŸ“„ License

MIT â€” see [LICENSE](LICENSE).
